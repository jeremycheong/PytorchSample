{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:1.12.1+cu113, cuda version:11.3, cuda is available:True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "\n",
    "print(f\"torch version:{torch.__version__}, cuda version:{torch.version.cuda}, cuda is available:{torch.cuda.is_available()}\")\n",
    "\n",
    "SplitLine = \"\\n==============================\\n\"\n",
    "\n",
    "def PrintTensor(name:str, x:Tensor):\n",
    "    print(f\"{name}:\\n\", x)\n",
    "    print(f\"{name}的维度数(秩):{x.dim()}; 形状:{x.shape}; 所在设备:{x.device}; 元素个数:{x.numel()}; 元素类型:{x.dtype}, 元素的字节大小:{x.element_size()}\", end=SplitLine)\n",
    "\n",
    "def PrintArray(name:str, x:np.ndarray):\n",
    "    print(f\"{name}:\\n\", x)\n",
    "    print(f\"{name}的维度数(秩):{x.ndim}; 元素类型：{x.dtype}; 数组的维度形状：{x.shape}; 元素个数：{x.size}; 元素的字节大小：{x.itemsize}\", end=SplitLine)\n",
    "\n",
    "# 与numpy相比，形状都为shape\n",
    "# 在numpy中，size是指所包含的元素个数；在pytorch中size依然为形状，其包含的元素个数为numel\n",
    "# 在numpy中，元素的字节大小为itemsize；在pytorch中为element_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor创建  \n",
    "|函数|功能|\n",
    "|:---|:---|\n",
    "|Tensor(*sizes)|基础构造函数|\n",
    "|tensor(data)|类似于np.array|\n",
    "|ones(*sizes)|全1|\n",
    "|zeros(*sizes)|全0|\n",
    "|eye(*sizes)|对角为1，其余为0|\n",
    "|arange(s,e,step)|从s到e，步长为step|\n",
    "|linspace(s,e,steps)|从s到e，均匀分成step份|\n",
    "|rand/randn(*sizes)|rand是[0,1)均匀分布；randn是服从N(0，1)的正态分布|\n",
    "|normal(mean,std)|正态分布(均值为mean，标准差是std)|\n",
    "|randperm(m)|随机排列|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* torch.Tensor与torch.tensor创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([3., 4.])\n",
      "a的维度数(秩):1; 形状:torch.Size([2]); 所在设备:cpu; 元素个数:2; 元素类型:torch.float32, 元素的字节大小:4\n",
      "==============================\n",
      "a1:\n",
      "tensor([[2.8026e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.4013e-45, 0.0000e+00]])\n",
      "a1的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.float32, 元素的字节大小:4\n",
      "==============================\n",
      "a2:\n",
      "tensor([3, 4])\n",
      "a2的维度数(秩):1; 形状:torch.Size([2]); 所在设备:cpu; 元素个数:2; 元素类型:torch.int64, 元素的字节大小:8\n",
      "==============================\n",
      "a3:\n",
      "tensor([[45.,  6.,  5., 40.],\n",
      "        [29., 16.,  3., 46.],\n",
      "        [11., 29., 30., 15.]])\n",
      "a3的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.float32, 元素的字节大小:4\n",
      "==============================\n",
      "a4:\n",
      "tensor([[45,  6,  5, 40],\n",
      "        [29, 16,  3, 46],\n",
      "        [11, 29, 30, 15]], device='cuda:0')\n",
      "a4的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cuda:0; 元素个数:12; 元素类型:torch.int64, 元素的字节大小:8\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "a = Tensor((3, 4))\n",
    "PrintTensor(\"a\", a)\n",
    "\n",
    "a1 = Tensor(3, 4)\n",
    "PrintTensor(\"a1\", a1)\n",
    "\n",
    "# tensor方法只能使用value形式创建张量\n",
    "a2 = torch.tensor((3, 4), dtype=torch.int64)\n",
    "PrintTensor(\"a2\", a2)\n",
    "\n",
    "# 此方法构建，两种方法默认的数据类型不同，Tensor方法数据默认为float32\n",
    "na = np.random.randint(0, 50, size=(3, 4))\n",
    "a3 = torch.Tensor(na)\n",
    "PrintTensor(\"a3\", a3)\n",
    "a4 = torch.tensor(na,device=\"cuda\")\n",
    "PrintTensor(\"a4\", a4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 创建特殊张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a0:\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "a0的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.float32, 元素的字节大小:4\n",
      "==============================\n",
      "a1:\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]])\n",
      "a1的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.int64, 元素的字节大小:8\n",
      "==============================\n",
      "a3:\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "a3的维度数(秩):2; 形状:torch.Size([3, 3]); 所在设备:cpu; 元素个数:9; 元素类型:torch.float32, 元素的字节大小:4\n",
      "==============================\n",
      "b3:\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "维度数(秩):2; 元素类型：float64; 数组的维度形状：(3, 4); 元素个数：12; 元素的字节大小：8\n",
      "==============================\n",
      "a4:\n",
      "tensor([[1.9524e-35, 0.0000e+00, 4.4634e-35, 0.0000e+00],\n",
      "        [7.2708e+31, 5.0778e+31, 3.2608e-12, 1.7728e+28],\n",
      "        [7.0367e+22, 2.1715e-18, 8.4030e+20, 1.0478e+21]])\n",
      "a4的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.float32, 元素的字节大小:4\n",
      "==============================\n",
      "a5:\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "a5的维度数(秩):1; 形状:torch.Size([12]); 所在设备:cpu; 元素个数:12; 元素类型:torch.int64, 元素的字节大小:8\n",
      "==============================\n",
      "a6:\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "a6的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.int64, 元素的字节大小:8\n",
      "==============================\n",
      "a7:\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "a7的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.int64, 元素的字节大小:8\n",
      "==============================\n",
      "a8:\n",
      "tensor([ 0.0000,  2.4000,  4.8000,  7.2000,  9.6000, 12.0000])\n",
      "a8的维度数(秩):1; 形状:torch.Size([6]); 所在设备:cpu; 元素个数:6; 元素类型:torch.float32, 元素的字节大小:4\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "a0 = torch.zeros((3, 4))\n",
    "PrintTensor(\"a0\", a0)\n",
    "\n",
    "a1 = torch.ones((3, 4), dtype=torch.int64)\n",
    "PrintTensor(\"a1\", a1)\n",
    "\n",
    "a3 = torch.eye(3)\n",
    "PrintTensor(\"a3\", a3)\n",
    "\n",
    "# torch中只能创建方阵的eye，numpy中可以创建行列不同的eye\n",
    "b3 = np.eye(3, 4)\n",
    "PrintArray(\"b3\", b3)\n",
    "\n",
    "a4 = torch.empty((3, 4))\n",
    "PrintTensor(\"a4\", a4)\n",
    "\n",
    "a5 = torch.arange(0, 12)\n",
    "PrintTensor(\"a5\", a5)\n",
    "# view只能在数据连续时使用\n",
    "# 在满足tensor连续性条件时，a.reshape返回的结果与a.view()相同，否则返回的结果与a.contiguous().view()相同\n",
    "a6 = a5.reshape((3, 4))\n",
    "PrintTensor(\"a6\", a6)\n",
    "a7 = a5.view((3, 4))\n",
    "PrintTensor(\"a7\", a7)\n",
    "\n",
    "a8 = torch.linspace(0, 12, 6)\n",
    "PrintTensor(\"a8\", a8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 随机张量创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([[0.3770, 0.3130, 0.1088, 0.9967],\n",
      "        [0.4683, 0.8490, 0.7908, 0.1349],\n",
      "        [0.4946, 0.0377, 0.7500, 0.8541]])\n",
      "a的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.float32, 元素的字节大小:4\n",
      "==============================\n",
      "a1:\n",
      "tensor([[ 1.6865,  0.9435, -0.5117, -0.3690],\n",
      "        [ 1.6485, -0.6723, -0.2845, -1.1416],\n",
      "        [-0.5012, -1.0045, -0.0452,  2.3697]])\n",
      "a1的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.float32, 元素的字节大小:4\n",
      "==============================\n",
      "a2:\n",
      "tensor([[ 2, 30, 14, 43],\n",
      "        [36, 45, 38,  9],\n",
      "        [42, 20, 24,  2]])\n",
      "a2的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.int64, 元素的字节大小:8\n",
      "==============================\n",
      "a3:\n",
      "tensor([[128.6178, 128.6328, 117.3280, 162.6013],\n",
      "        [162.6561, 104.6757, 142.3671,  95.0242],\n",
      "        [154.9756, 160.0784, 118.6222, 102.1500]])\n",
      "a3的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.float32, 元素的字节大小:4\n",
      "==============================\n",
      "a4:\n",
      "tensor([ 1,  3, 12, 18,  8, 14, 11, 15,  0,  7,  6, 17,  2,  4,  5, 16,  9, 19,\n",
      "        10, 13])\n",
      "a4的维度数(秩):1; 形状:torch.Size([20]); 所在设备:cpu; 元素个数:20; 元素类型:torch.int64, 元素的字节大小:8\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((3, 4))\n",
    "PrintTensor(\"a\", a)\n",
    "a1 = torch.randn((3, 4))\n",
    "PrintTensor(\"a1\", a1)\n",
    "a2 = torch.randint(0, 50, size=(3, 4))\n",
    "PrintTensor(\"a2\", a2)\n",
    "\n",
    "mean = 127.5\n",
    "std = 20.\n",
    "a3 = torch.normal(mean, std, size=(3, 4))\n",
    "PrintTensor(\"a3\", a3)\n",
    "\n",
    "a4 = torch.randperm(20)\n",
    "PrintTensor(\"a4\", a4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 从numpy数组/list创建张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na:\n",
      "[[11 19 18 16]\n",
      " [19  2  2 12]\n",
      " [18  8 14 12]]\n",
      "维度数(秩):2; 元素类型：int64; 数组的维度形状：(3, 4); 元素个数：12; 元素的字节大小：8\n",
      "==============================\n",
      "a:\n",
      "tensor([[11., 19., 18., 16.],\n",
      "        [19.,  2.,  2., 12.],\n",
      "        [18.,  8., 14., 12.]])\n",
      "a的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.float32, 元素的字节大小:4\n",
      "==============================\n",
      "a1:\n",
      "tensor([[11, 19, 18, 16],\n",
      "        [19,  2,  2, 12],\n",
      "        [18,  8, 14, 12]])\n",
      "a1的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.int64, 元素的字节大小:8\n",
      "==============================\n",
      "a2:\n",
      "tensor([[11, 19, 18, 16],\n",
      "        [19,  2,  2, 12],\n",
      "        [18,  8, 14, 12]])\n",
      "a2的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.int64, 元素的字节大小:8\n",
      "==============================\n",
      "a3:\n",
      "tensor([[11, 19, 18, 16],\n",
      "        [19,  2,  2, 12],\n",
      "        [18,  8, 14, 12]])\n",
      "a3的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.int64, 元素的字节大小:8\n",
      "==============================\n",
      "a4:\n",
      "tensor([[11, 19, 18, 16],\n",
      "        [19,  2,  2, 12],\n",
      "        [18,  8, 14, 12]])\n",
      "a4的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.int64, 元素的字节大小:8\n",
      "==============================\n",
      "la:\n",
      " [[11, 19, 18, 16], [19, 2, 2, 12], [18, 8, 14, 12]]\n",
      "b:\n",
      "tensor([[11., 19., 18., 16.],\n",
      "        [19.,  2.,  2., 12.],\n",
      "        [18.,  8., 14., 12.]])\n",
      "b的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.float32, 元素的字节大小:4\n",
      "==============================\n",
      "b1:\n",
      "tensor([[11, 19, 18, 16],\n",
      "        [19,  2,  2, 12],\n",
      "        [18,  8, 14, 12]])\n",
      "b1的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.int64, 元素的字节大小:8\n",
      "==============================\n",
      "b2:\n",
      "tensor([[11, 19, 18, 16],\n",
      "        [19,  2,  2, 12],\n",
      "        [18,  8, 14, 12]])\n",
      "b2的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.int64, 元素的字节大小:8\n",
      "==============================\n",
      "b3:\n",
      "tensor([[11, 19, 18, 16],\n",
      "        [19,  2,  2, 12],\n",
      "        [18,  8, 14, 12]])\n",
      "b3的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.int64, 元素的字节大小:8\n",
      "==============================\n",
      "s:\n",
      "[[11. 19. 18. 16.]\n",
      " [19.  2.  2. 12.]\n",
      " [18.  8. 14. 12.]]\n",
      "维度数(秩):2; 元素类型：float32; 数组的维度形状：(3, 4); 元素个数：12; 元素的字节大小：4\n",
      "==============================\n",
      "l:\n",
      " [[11.0, 19.0, 18.0, 16.0], [19.0, 2.0, 2.0, 12.0], [18.0, 8.0, 14.0, 12.0]]\n"
     ]
    }
   ],
   "source": [
    "na = np.random.randint(1, 20, size=(3, 4))\n",
    "PrintArray(\"na\", na)\n",
    "\n",
    "a = torch.Tensor(na)\n",
    "PrintTensor(\"a\", a)\n",
    "a1 = torch.tensor(na)\n",
    "PrintTensor(\"a1\", a1)\n",
    "a2 = torch.from_numpy(na)\n",
    "PrintTensor(\"a2\", a2)\n",
    "a3 = torch.as_tensor(na)\n",
    "PrintTensor(\"a3\", a3)\n",
    "a4 = torch.asarray(na)\n",
    "PrintTensor(\"a4\", a4)\n",
    "\n",
    "# numpy ndarray 转list\n",
    "la = na.tolist()\n",
    "\n",
    "print(\"la:\\n\", la)\n",
    "b = torch.Tensor(la)\n",
    "PrintTensor(\"b\", b)\n",
    "b1 = torch.tensor(la)\n",
    "PrintTensor(\"b1\", b1)\n",
    "b2 = torch.as_tensor(la)\n",
    "PrintTensor(\"b2\", b2)\n",
    "b3 = torch.asarray(la)\n",
    "PrintTensor(\"b3\", b3)\n",
    "\n",
    "# Tensor转ndarray\n",
    "s = a.numpy()\n",
    "PrintArray(\"s\", s)\n",
    "\n",
    "# Tensor转list\n",
    "l = a.tolist()\n",
    "print(\"l:\\n\", l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 张量的元素标量值访问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " tensor([[11., 19., 18., 16.],\n",
      "        [19.,  2.,  2., 12.],\n",
      "        [18.,  8., 14., 12.]])\n",
      "a的维度数(秩):2; 形状:torch.Size([3, 4]); 所在设备:cpu; 元素个数:12; 元素类型:torch.float32, 元素的字节大小:4\n",
      "==============================\n",
      "a_mean:\n",
      " tensor(12.5833)\n",
      "a_mean的维度数(秩):0; 形状:torch.Size([]); 所在设备:cpu; 元素个数:1; 元素类型:torch.float32, 元素的字节大小:4\n",
      "==============================\n",
      "a_val type:  <class 'float'>\n",
      "a_val:\n",
      " 12.583333015441895\n",
      "a_11 Tensor:\n",
      " tensor(2.)\n",
      "a_11 Tensor的维度数(秩):0; 形状:torch.Size([]); 所在设备:cpu; 元素个数:1; 元素类型:torch.float32, 元素的字节大小:4\n",
      "==============================\n",
      "a_11:\n",
      " 2.0\n",
      "a_mean_0:\n",
      " tensor([16.0000,  9.6667, 11.3333, 13.3333])\n",
      "a_mean_0的维度数(秩):1; 形状:torch.Size([4]); 所在设备:cpu; 元素个数:4; 元素类型:torch.float32, 元素的字节大小:4\n",
      "==============================\n",
      "a_mean_0 ndarray:\n",
      " [16.        9.666667 11.333333 13.333333]\n",
      "a_mean_0 ndarray的维度数(秩):1; 元素类型：float32; 数组的维度形状：(4,); 元素个数：4; 元素的字节大小：4\n",
      "==============================\n",
      "a_mean_1:\n",
      " tensor([16.0000,  8.7500, 13.0000])\n",
      "a_mean_1的维度数(秩):1; 形状:torch.Size([3]); 所在设备:cpu; 元素个数:3; 元素类型:torch.float32, 元素的字节大小:4\n",
      "==============================\n",
      "a_mean_1 list:\n",
      " [16.0, 8.75, 13.0]\n"
     ]
    }
   ],
   "source": [
    "PrintTensor(\"a\", a)\n",
    "\n",
    "a_mean = a.mean()\n",
    "PrintTensor(\"a_mean\", a_mean)\n",
    "\n",
    "# item方法只有当Tensor中含有一个元素时可用\n",
    "a_val = a_mean.item()\n",
    "print(\"a_val type: \", type(a_val))\n",
    "print(\"a_val:\\n\", a_val)\n",
    "\n",
    "a_11 = a[1][1]\n",
    "PrintTensor(\"a_11 Tensor\", a_11)\n",
    "print(\"a_11:\\n\", a_11.item())\n",
    "\n",
    "# 访问多个标量值需要将其转成numpy或者list\n",
    "a_mean_0 = a.mean(dim=0)\n",
    "PrintTensor(\"a_mean_0\", a_mean_0)\n",
    "PrintArray(\"a_mean_0 ndarray\", a_mean_0.numpy())\n",
    "a_mean_1 = a.mean(dim=1)\n",
    "PrintTensor(\"a_mean_1\", a_mean_1)\n",
    "print(\"a_mean_1 list:\\n\", a_mean_1.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
